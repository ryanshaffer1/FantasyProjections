"""Creates and exports functions to be used in NFL player statistics data collection.

    Functions:
        validata_parsed_data : Compares the final statistics generated by play-by-play parsing to true statistics scraped from the internet.
"""  # fmt: skip

import logging
from datetime import datetime

import matplotlib.pyplot as plt
import pandas as pd
from config import data_files_config, stats_config
from config.player_id_config import fill_blank_player_ids
from data_pipeline.stats_pipeline.scrape_pro_football_reference import scrape_box_score
from data_pipeline.utils import team_abbreviations as team_abbrs
from data_pipeline.utils.data_helper_functions import construct_game_id
from misc.manage_files import create_folders

# Set up logger
logger = logging.getLogger("log")


def validate_parsed_data(final_stats_df, urls_df, scrape=False, save_data=False):
    """Compares the final statistics generated by play-by-play parsing to true statistics scraped from the internet.

        This ensures that the play-by-play parsing is correct when summed up over each game, though there may still be errors in the midgame stats
        that cancel out when summed up over the game (e.g. attributing stats to the wrong play, missing a yard here and gaining a yard there, etc.)

        Args:
            final_stats_df (pandas.DataFrame): Game statistics generated by data pipeline (play-by-play parsing).
            urls_df (pandas.DataFrame): Maps game_id to URL to scrape stats from pro-football-reference.com
            scrape (bool, optional): Whether to scrape missing data from pro-football-reference.com. Defaults to False.
            save_data (bool, optional): Whether to save scraped statistics and comparison against parsed statistics to csv files. Defaults to False.
    """  # fmt: skip

    last_req_time = datetime.now().astimezone()

    # Pre-process input
    urls_df = urls_df.drop_duplicates(keep="first")

    # Read saved truth data
    try:
        true_df = pd.read_csv(data_files_config.TRUE_STATS_FILE).set_index(["pfr_id", "Year", "Week"])
    except FileNotFoundError:
        logger.warning("True Stats data file not found! Building from scratch.")
        true_df = pd.DataFrame()

    # Compare saved truth data to input data to determine whether any saved truth data is missing
    missing_games, _ = __identify_missing_games(final_stats_df, true_df, fill_missing_data=False)

    # Add PFR ID to any players in the parsed database that are missing it
    final_stats_df = fill_blank_player_ids(
        players_df=final_stats_df,
        master_id_file=data_files_config.MASTER_PLAYER_ID_FILE,
        pfr_id_filename=data_files_config.PFR_ID_FILENAME,
        add_missing_pfr=scrape,
        update_master=save_data,
    )

    if scrape and len(missing_games) > 0:
        logger.info("Scraping web data:")

        # Scrape the corresponding stat URLs
        for i, (game_id, row) in enumerate(missing_games.iterrows()):
            team_abbrevs = team_abbrs.convert_abbrev(
                row[["Team", "Opponent"]].to_list(),
                team_abbrs.pbp_abbrevs,
                team_abbrs.boxscore_website_abbrevs,
            )
            game_url = urls_df.loc[game_id, "PFR URL"]
            logger.info(f"({i + 1} of {len(missing_games)}) {game_id} from {game_url}")
            boxscore, last_req_time = scrape_box_score(game_url, team_abbrevs, last_req_time)

            boxscore[["Year", "Week"]] = row.loc[["Year", "Week"]].to_list()
            boxscore = boxscore.set_index(["pfr_id", "Year", "Week"])
            true_df = pd.concat((true_df, boxscore))

        # Log number of remaining missing players/games
        _, true_df = __identify_missing_games(final_stats_df, true_df, fill_missing_data=True)

        # Remove any unwanted duplicates from the resulting dataframe
        true_df = true_df.reset_index().drop_duplicates(keep="first").set_index(["pfr_id", "Year", "Week"])
        # Save updated dataframe for use next time
        if save_data:
            create_folders(data_files_config.TRUE_STATS_FILE)
            true_df.to_csv(data_files_config.TRUE_STATS_FILE)
            logger.info(f"Saved data to {data_files_config.TRUE_STATS_FILE}.")

    # List of statistics to compute differences between truth and parsed data
    stats = stats_config.default_stat_list
    # Generate df of comparison (difference between truth and parsed)
    diff_df = __compare_dfs(true_df, final_stats_df, stats)

    # Log comparison performance
    __print_validation_comparison(diff_df, stats)

    # Optionally save dataframe to a csv
    if save_data:
        create_folders(data_files_config.PARSING_VALIDATION_FILE)
        diff_df.to_csv(data_files_config.PARSING_VALIDATION_FILE)

    # Plot differences between truth and parsed data
    __plot_validation_comparison(diff_df, stats)


def __identify_missing_games(final_stats_df, true_df, fill_missing_data=False):
    final_stats_df = final_stats_df.copy()  # Copy df before manipulating it
    final_stats_df = final_stats_df.reset_index().set_index(["pfr_id", "Year", "Week"])

    # Compare saved truth data to input data to determine whether any saved truth data is missing
    missing_players = final_stats_df.index.difference(true_df.index)
    # Gather unique game IDs that are missing
    missing_games = final_stats_df.loc[missing_players].reset_index()  # Filter to only the missing players
    missing_games["Game ID"] = missing_games.apply(construct_game_id, axis=1)
    missing_games = missing_games.drop_duplicates(subset=["Game ID"], keep="first").set_index("Game ID")
    logger.info(f"Truth Data missing {len(missing_players)} players from {len(missing_games)} games.")

    if fill_missing_data:
        logger.info("Assigning 0 to all missing player stats.")
        true_df = pd.concat((true_df, final_stats_df.loc[missing_players, ["Player Name", "Team"]]))
        with pd.option_context("future.no_silent_downcasting", True):
            true_df = true_df.fillna(0)

    return missing_games, true_df


def __compare_dfs(true_df, final_stats_df, stats):
    # Merge dataframes and compute differences in statistics
    merged_df = true_df.reset_index().merge(final_stats_df.reset_index(), how="inner", on=["pfr_id", "Year", "Week"])
    for stat in stats:
        merged_df[f"{stat}_diff"] = merged_df[f"{stat}_y"] - merged_df[f"{stat}_x"]  # Estimated minus truth
    diff_df = merged_df[["pfr_id", "Player Name_x", "Year", "Week"] + [s + "_diff" for s in stats]]

    return diff_df


def __plot_validation_comparison(diff_df, stats):
    x = [list(range(len(stats))) for _ in range(diff_df.shape[0])]
    y = diff_df[[s + "_diff" for s in stats]].stack()

    _, ax = plt.subplots(1, 1)
    ax.scatter(x, y)
    ax.set_ylabel("Difference, Truth - Parsed Data")
    ax.set_xticks(range(len(stats)))
    ax.set_xticklabels(stats)
    for label in ax.get_xticklabels():
        label.set(rotation=45, horizontalalignment="right")
    ax.set_title("Play-By-Play Parsing Validation vs. True Statlines")

    plt.show(block=False)


def __print_validation_comparison(diff_df, stats):
    # Log comparison performance
    stats_diffs = diff_df[[s + "_diff" for s in stats]]
    avg_diffs = stats_diffs.mean()
    num_nonzero = stats_diffs.astype(bool).sum()
    logger.info(
        f"Number of differences between parsed and true data: {num_nonzero.sum()} ({100 * num_nonzero.sum() / stats_diffs.size:.2f}%)",
    )
    logger.debug(f"Number of differences by stat: \n{num_nonzero}")
    logger.debug(f"Average difference by stat: \n{avg_diffs}")
