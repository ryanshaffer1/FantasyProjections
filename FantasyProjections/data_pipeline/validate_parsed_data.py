"""Creates and exports functions to be used in NFL player statistics data collection.

    Functions:
        validata_parsed_data : Compares the final statistics generated by play-by-play parsing to true statistics scraped from the internet.
"""
from datetime import datetime
import logging
import matplotlib.pyplot as plt
import pandas as pd
from config import data_files_config, stats_config
from data_pipeline.scrape_pro_football_reference import scrape_box_score
from data_pipeline import team_abbreviations
from data_pipeline.data_helper_functions import construct_game_id
from misc.manage_files import create_folders

# Set up logger
logger = logging.getLogger('log')

def validate_parsed_data(final_stats_df, urls_df, scrape=False, save_data=False):
    """Compares the final statistics generated by play-by-play parsing to true statistics scraped from the internet.
    
        This ensures that the play-by-play parsing is correct when summed up over each game, though there may still be errors in the midgame stats
        that cancel out when summed up over the game (e.g. attributing stats to the wrong play, missing a yard here and gaining a yard there, etc.)

        Args:
            final_stats_df (pandas.DataFrame): Game statistics generated by data pipeline (play-by-play parsing).
            urls_df (pandas.DataFrame): Maps game_id to URL to scrape stats from pro-football-reference.com
            scrape (bool, optional): Whether to scrape missing data from pro-football-reference.com. Defaults to False.
            save_data (bool, optional): Whether to save scraped statistics and comparison against parsed statistics to csv files. Defaults to False.
    """

    last_req_time = datetime.now()

    # Pre-process input
    urls_df = urls_df.drop_duplicates(keep='first')

    # Read saved truth data
    try:
        true_df = pd.read_csv(data_files_config.TRUE_STATS_FILE).set_index(['Player','Year','Week'])
    except FileNotFoundError:
        true_df = pd.DataFrame(columns=final_stats_df.reset_index().columns).set_index(['Player','Year','Week'])

    # Compare saved truth data to input data to determine whether any saved truth data is missing
    missing_games = __identify_missing_games(final_stats_df, true_df)

    if scrape and len(missing_games) > 0:
        logger.info('Scraping web data:')
        # Scrape the corresponding stat URLs
        for i, (_, row) in enumerate(missing_games.iterrows()):
            team_abbrevs = team_abbreviations.convert_abbrev(row[['Team','Opponent']].to_list(),
                                                            team_abbreviations.pbp_abbrevs,
                                                            team_abbreviations.boxscore_website_abbrevs)
            game_url = urls_df.loc[row['Game ID'],'PFR URL']
            logger.info(f'({i+1} of {len(missing_games)}) {row['Game ID']} from {game_url}')
            boxscore, last_req_time = scrape_box_score(game_url, team_abbrevs, last_req_time)

            boxscore[['Year', 'Week']] = row.loc[['Year', 'Week']].to_list()
            boxscore = boxscore.reset_index().set_index(['Player','Year','Week'])
            true_df = pd.concat((true_df, boxscore))

        # Log number of remaining missing players/games
        __identify_missing_games(final_stats_df, true_df)

        # Remove any unwanted duplicates from the resulting dataframe
        true_df = true_df.reset_index().drop_duplicates(keep='first').set_index(['Player','Year','Week'])
        # Save updated dataframe for use next time
        if save_data:
            create_folders(data_files_config.TRUE_STATS_FILE)
            true_df.to_csv(data_files_config.TRUE_STATS_FILE)
            logger.info(f'Saved data to {data_files_config.TRUE_STATS_FILE}.')

    # List of statistics to compute differences between truth and parsed data
    stats = stats_config.default_stat_list
    # Generate df of comparison (difference between truth and parsed)
    diff_df = __compare_dfs(true_df, final_stats_df, stats)

    # Log comparison performance
    stats_diffs = diff_df[[s+'_diff' for s in stats]]
    avg_diffs = stats_diffs.mean()
    num_nonzero = stats_diffs.astype(bool).sum()
    logger.info(f'Number of differences between parsed and true data: {num_nonzero.sum()} ({100*num_nonzero.sum()/stats_diffs.size:.2f}%)')
    logger.debug(f'Number of differences by stat: \n{num_nonzero}')
    logger.debug(f'Average difference by stat: \n{avg_diffs}')

    # Optionally save dataframe to a csv
    if save_data:
        create_folders(data_files_config.PARSING_VALIDATION_FILE)
        diff_df.to_csv(data_files_config.PARSING_VALIDATION_FILE)

    # Plot differences between truth and parsed data
    __plot_validation_comparison(diff_df, stats)


def __identify_missing_games(final_stats_df, true_df):
    # Compare saved truth data to input data to determine whether any saved truth data is missing
    missing_players = final_stats_df.index.difference(true_df.index)
    # Gather unique game IDs that are missing
    missing_games = final_stats_df.copy().loc[missing_players].reset_index() # Copy df before manipulating it, then filter to only the missing players
    missing_games['Game ID'] = missing_games.apply(construct_game_id, axis=1)
    missing_games = missing_games.drop_duplicates(subset=['Game ID'],keep='first')
    logger.info(f'Truth Data missing {len(missing_players)} players from {len(missing_games)} games.')

    return missing_games


def __compare_dfs(true_df, final_stats_df, stats):
    # Merge dataframes and compute differences in statistics
    merged_df = pd.merge(
        true_df.reset_index(), final_stats_df.reset_index(), how='inner', on=[
            'Player', 'Year', 'Week'])
    for stat in stats:
        merged_df[f'{stat}_diff'] = merged_df[f'{stat}_y'] - \
            merged_df[f'{stat}_x']  # Estimated minus truth
    diff_df = merged_df[['Player', 'Year', 'Week'] + [s + '_diff' for s in stats]]

    return diff_df


def __plot_validation_comparison(diff_df, stats):
    x = []
    for _ in range(diff_df.shape[0]):
        for i in range(len(stats)):
            x.append(i)
    y = diff_df[[s + '_diff' for s in stats]].stack()

    _, ax = plt.subplots(1, 1)
    ax.scatter(x, y)
    ax.set_ylabel('Difference, Truth - Parsed Data')
    ax.set_xticks(range(len(stats)))
    ax.set_xticklabels(stats)
    for label in ax.get_xticklabels():
        label.set(rotation=45, horizontalalignment='right')
    ax.set_title('Play-By-Play Parsing Validation vs. True Statlines')

    plt.show(block=False)
